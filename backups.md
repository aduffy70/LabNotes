---
title: Backups
date: 2011-07-01T11:05:29+00:00
layout: page
---
# Strategy

## Categories of files

On my main desktop (fiddlehead):
  * Active files - for active projects. These get changed or updated frequently. This includes my LabNotes files.
  * Archived files - for completed, abandoned, or postponed projects. These seldom change and if they are getting changed often they should be moved back to active files.
  * Large data files - these are original raw data files (_e.g._, raw Illumina sequence data) that should never change.  
  * Backups - these are copies of files backed up from my webserver or Google Drive/Gmail (see below).
  * Shared Shaw Lab files - these are my local copies of the Shaw Lab Dropbox folders.

On Google Drive:
  * Lab files (collection records, primer records, lab setup sheets, and borrowed or manufacturers' protocols). These are things I need to be able to access in the lab and some get changed or updated frequently.

On my webserver:
  * VPCsim files. These rarely change.

On computing clusters:
  * Large analysis files - files from large data analysis projects. This could include cleaned, trimmed, or otherwise processed sequence data, and files generated by analysis software.

## Backup schedules

### Backed up continuously/automatically in the cloud:

  * Through Dropbox:
    - Active files (sync to my laptop)
    - Archived files (sync to my laptop)
    - Large data files (not on laptop--too large)
    - Shared Shaw Lab files (not on laptop--too large)
  * Through Google Drive:
    - Lab files

### Backed up automatically every 4 hours on a second harddrive in fiddlehead (BACKPACK):

  * Active files
  * Archived files
  * Large data files
  * Backups
  * Shared Shaw Lab files

### Backed up automatically every night:

  * On my offsite server (crozier):
    - Active files
    - Archived files
    - Backups
  * On the Shared Shaw Lab dropbox folder (for sharing, more than backup purposes):
    - Shaw Lab-related Active files
    - Shaw Lab-related Archived files

### Backed up manually once a month:

  * On an external drive only attached during the backup (CAMEL):
    - Active files
    - Archived files
    - Backups
  * On fiddlehead (these become the "Backups" referred to above):
    - Lab files from Google Drive
    - Emails, contacts, and calendars from Google
    - VPCsim files from my webserver
  * On the Shared Shaw Lab dropbox folder (for sharing, more than backup purposes):
    - Shaw Lab-related Lab files from Google Drive

### Backed up manually when received:

   * On an external drive (BIGDISK) only attached during the backup and on one or more computing clusters:
    - Large data files

### Backed up manually as needed:

  * On an external drive (BIGDISK) or moved to Active or Archived folders on fiddlehead:
    - Large analysis files from computing clusters


# Backup process

## 4 hour backups and nightly backups

  Performed automatically by cron job

## Monthly backups

### 1) Verify automatic backups

  * Confirm a recently created/updated file on BACKPACK.
  * Confirm a recently created/updated file on the Shared Shaw Lab dropbox folder
  * Confirm a recently created/updated file on crozier.

### 2) Backup Google stuff

  * On fiddlehead, download a zip file of all Google Drive documents (select all folders/files, right-click and select Download)

~~~
mv ~/Downloads/drive-download* ~/Backups/GoogleDocs/
~~~

  * Also download a zip file of just Shaw Lab-related Google Drive documents:
    * Protocols and References folder
    * Others?

~~~
 mv ~/Downloads/drive-download* ~/Dropbox/Shaw\ Lab/Aaron/GoogleDrive_backup
~~~

  * On fiddlehead, download a zip file of Gmail messages, Contacts and Google Calendar events. (Visit <https://takeout.google.com/settings/takeout> )

~~~
mv ~/Downloads/takeout* ~/Backups/Gmail/
~~~

### 3) Backup server stuff

  * Backup VPCsim site on crozier

~~~
mkdir Backups/crozier.$(date +%Y%m%d)
tar czf Backups/crozier.$(date +%Y%m%d)/public_html5.tgz public_html5/
~~~

  * From fiddlehead, copy crozier backup to fiddlehead

~~~
scp -r -P port user@ip:Backups/crozier.$(date +%Y%m%d) ~/Backups/
~~~

### 4) Backup to an external drive

  * Backup fiddlehead home directory to CAMEL

~~~
weeklybackup
~~~

# Commands and scripts to support the steps above

Cron jobs for 4 hour and nightly backups:

~~~
# m h  dom mon dow   command
0 */4 * * * /usr/local/bin/make_backup.sh > /dev/null
00 3 * * * /usr/local/bin/make_backup-shaw_lab.sh > /dev/null
30 1 * * * /usr/local/bin/offsite_backup.sh > /dev/null
~~~

Scripts:

~~~
#! /bin/bash
# make_backup.sh
# Backs up my home folder to my second drive. Exclude Shares (Coulombe Lab Tox drive) and cache files
rsync -qaz --delete --exclude=".gvfs/" --exclude="Shares" --exclude=".dbus" --exclude=".cache" /home/aduffy /media/aduffy/BACKPACK/rsyncbackup/ ;
eval "export $(egrep -z DBUS_SESSION_BUS_ADDRESS /proc/$(pgrep -u $LOGNAME gnome-session)/environ)";
notify-send -i stock_new-appointment "Local backup complete..." ;
~~~

~~~
#! /bin/bash
# make_backup-shaw_lab.sh
# Backs up my Shaw lab current and archived folders to the my subfolder in the Shared Shaw Lab Dropbox folder     

rsync -qaz --delete /home/aduffy/Dropbox/My_Shaw_Lab/ /home/aduffy/Dropbox/Shaw\ Lab/Aaron/Active ;
rsync -qaz --delete /home/aduffy/Dropbox/Archived/Shaw_Lab_archived/ /home/aduffy/Dropbox/Shaw\ Lab/Aaron/Archived ;                                                     
eval "export $(egrep -z DBUS_SESSION_BUS_ADDRESS /proc/$(pgrep -u $LOGNAME gnome-session)/environ)";
notify-send -i stock_new-appointment "Shaw Lab backup complete..." ;
~~~

~~~
#! /bin/bash
# offsite_backup.sh
# Backs up critical subfolders of my home folder to a server in another building

# Let's do everything rather than just specific folders

rsync -aqz -e "ssh -p port" --delete --exclude=".ssh/" --exclude="Shares" --exclude="Dropbox (Duke Bio_Ea)/Data" --exclude="Dropbox (Duke Bio_Ea)/Shaw Lab" --exclude=".smbcredentials" --exclude=".dbus" --exclude=".cache" /home/aduffy/ user@ip:/home/aduffy/fiddleheadBackup-rsync/

eval "export $(egrep -z DBUS_SESSION_BUS_ADDRESS /proc/$(pgrep -u $LOGNAME gnome-session)/environ)";
notify-send -i stock_new-appointment "Offsite backup complete..." ;
~~~

  * weekly backup command (used in the monthly backup--there is no weekly backup anymore):

~~~
alias weeklybackup='sudo /usr/local/bin/weeklybackupnew.sh'
~~~

~~~
#! /bin/bash
# weeklybackupnew.sh
# Backs up critical subfolders of my home folder to my external drive

# Let's do everything rather than just specific folders
rsync -azv -e --delete --exclude=".ssh/" --exclude="Shares" --exclude="Dropbox (Duke Bio_Ea)/Data" --exclude="Dropbox (Duke Bio_Ea)/Shaw Lab" --exclude=".smbcredentials" --exclude=".dbus" --exclude=".cache" /home/aduffy /media/aduffy/CAMEL/fiddleheadBackup-rsync/ ;
~~~
